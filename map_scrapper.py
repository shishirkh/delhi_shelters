# -*- coding: utf-8 -*-
"""map_scrapper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jKANFqr71xNB9UDb8kWw1d2hFsljdU_d
"""

!pip install requests
!pip install html5lib
!pip install bs4

import requests 
from bs4 import BeautifulSoup 
import re
import pandas as pd

#URL = "http://delhishelterboard.in/occupancy-report/index-ag2.php?fbclid=IwAR0F4l2Dto-CS8PtD7URKbDU6eUFcoDxTGZ0cHObENnZvYYr-fvfQS5CJo8"
#URL = "http://delhishelterboard.in/night-shelter/map/?fbclid=IwAR17f68wRre0iGJtjIU-wBUelzkujhC3B9NqTNrkH0gGIgFTn7JRTF9uWTs"
URL = "http://delhishelterboard.in/night-shelter/map/?fbclid=IwAR2zt9AyWRX_KXJOww5DpUnILtGccO0dQTud2fosM0hMQUq0Xm8V61YaPJU"

r = requests.get(URL) 
soup = BeautifulSoup(r.content, 'html5lib')
recs = soup.findAll('li') 

rows_list=[]
df = pd.DataFrame(columns=['code'])

for i in range (0,len(recs)):
  item1=recs[i]
  item=str(item1)
  x = re.findall("(http|ftp|https)://([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?",item) 
  if(len(x) > 0):
    link=x[0][0]+"://"+x[0][1]+x[0][2]
    y=item1.findAll('a')
    NS_code=y[0].text
    #print(link,NS_code)
    df = df.append({'code':NS_code,'link':link}, ignore_index=True)
    
print(df)
df.to_csv('link_and_code_26th_march.csv', index=False)